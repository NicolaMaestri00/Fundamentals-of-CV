{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ2Ut3fVv9Lx"
      },
      "source": [
        "# Finetuning AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fgoxxp8v9ME"
      },
      "source": [
        "Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B6OIsa2sv9ME"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CostumDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_dir, img_size=100, augmentation=False):\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.img_size = img_size\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "        img_data = []\n",
        "        labels = []\n",
        "        dirs = []\n",
        "        for i, folder in enumerate(os.listdir(img_dir)):\n",
        "            dirs.append(folder)\n",
        "            for img in glob.glob(os.path.join(img_dir, folder, \"*.jpg\")):\n",
        "                img_data.append(cv2.imread(img))\n",
        "                labels.append(i)\n",
        "\n",
        "        self.images = img_data\n",
        "        self.labels = labels\n",
        "        self.class_names = dirs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transform_list = list()\n",
        "        transform_list.append(T.ToTensor())\n",
        "        transform_list.append(T.Resize(self.img_size))\n",
        "        if self.augmentation == True:\n",
        "            BILINEAR = T.InterpolationMode.BILINEAR\n",
        "            aug_trans = [torchvision.transforms.RandomPerspective(interpolation=BILINEAR),\n",
        "                  torchvision.transforms.RandomRotation(15, interpolation=BILINEAR),\n",
        "                  torchvision.transforms.RandomHorizontalFlip(),\n",
        "                  torchvision.transforms.RandomErasing()]\n",
        "            transform_list.extend(aug_trans)\n",
        "\n",
        "        data_transforms = T.Compose(transform_list)\n",
        "        image = data_transforms(image)\n",
        "        return image, label\n",
        "\n",
        "    def get_class_names(self):\n",
        "        return self.class_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWYlYakDv9MF"
      },
      "source": [
        "Finetuned AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yi99tp6hv9MF"
      },
      "outputs": [],
      "source": [
        "def initialize_alexnet(num_classes):\n",
        "  # load the pre-trained Alexnet\n",
        "  alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "  # get the number of neurons in the second last layer\n",
        "  in_features = alexnet.classifier[6].in_features\n",
        "\n",
        "  # re-initalize the output layer\n",
        "  alexnet.classifier[6] = torch.nn.Linear(in_features=in_features,\n",
        "                                          out_features=num_classes)\n",
        "\n",
        "  return alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sqLumIDKv9MG"
      },
      "outputs": [],
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gKdTZD_Nv9MG"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, lr, wd, momentum):\n",
        "  # two groups of weights, one for the newly initialized layer and the other for rest of the layers of the network\n",
        "\n",
        "  final_layer_weights = []\n",
        "  rest_of_the_net_weights = []\n",
        "\n",
        "  # iterate through the layers of the network\n",
        "  for name, param in model.named_parameters():\n",
        "    if name.startswith('classifier.6'):\n",
        "      final_layer_weights.append(param)\n",
        "    else:\n",
        "      rest_of_the_net_weights.append(param)\n",
        "\n",
        "  # distinct learning rates to each group of parameters\n",
        "  optimizer = torch.optim.SGD([\n",
        "      {'params': rest_of_the_net_weights},\n",
        "      {'params': final_layer_weights, 'lr': lr}\n",
        "  ], lr=lr / 10, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBs1RzVv9MH"
      },
      "source": [
        "Traning and Test Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaWrrTnZv9MH"
      },
      "outputs": [],
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n",
        "  samples = 0.0\n",
        "  cumulative_loss = 0.0\n",
        "  cumulative_accuracy = 0.0\n",
        "\n",
        "  net.train()\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = cost_function(outputs,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    samples += inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1)\n",
        "\n",
        "    # compute training accuracy\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "def test_step(net, data_loader, cost_function, device='cuda'):\n",
        "  samples = 0.0\n",
        "  cumulative_loss = 0.0\n",
        "  cumulative_accuracy = 0.0\n",
        "\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(1)\n",
        "\n",
        "      # compute accuracy\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR7l41r9v9MI"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnSoVdudv9MI",
        "outputId": "3526b62e-d262-4954-97e1-f8c23dcf8d63"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'CostumDataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m   device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# instantiates datasets\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m full_training_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCostumDataset\u001b[49m(img_dir_train, \u001b[38;5;241m100\u001b[39m, augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m scene_dataset_test \u001b[38;5;241m=\u001b[39m CostumDataset(img_dir_test, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# instantiates dataloaders\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'CostumDataset' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as TabError\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 4\n",
        "learning_rate=0.001\n",
        "weight_decay=0.000001\n",
        "momentum=0.9\n",
        "epochs=50\n",
        "num_classes = 10\n",
        "\n",
        "img_dir_train = 'data/scene/train'\n",
        "img_dir_test = 'data/scene/test'\n",
        "\n",
        "# device to use\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda:0'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "\n",
        "# instantiates datasets\n",
        "full_training_dataset = CostumDataset(img_dir_train, 100, augmentation=True)\n",
        "scene_dataset_test = CostumDataset(img_dir_test, 100)\n",
        "\n",
        "# instantiates dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(full_training_dataset, batch_size= batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(scene_dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# instantiates the model\n",
        "net = initialize_alexnet(num_classes=num_classes).to(device)\n",
        "\n",
        "# instantiates the optimizer\n",
        "optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "\n",
        "# instantiates the cost function\n",
        "cost_function = get_cost_function()\n",
        "\n",
        "# perform a preliminar step\n",
        "print('Before training:')\n",
        "train_loss, train_accuracy = test_step(net, train_loader, cost_function, device=device)\n",
        "# test_loss, test_accuracy = test_step(net, test_loader, cost_function, device=device)\n",
        "print('\\tTraining loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "# print('\\tTest loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "print('-----------------------------------------------------')\n",
        "\n",
        "epochs=50\n",
        "for e in range(epochs):\n",
        "  train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device=device)\n",
        "  # test_loss, test_accuracy = test_step(net, test_loader, cost_function, device=device)\n",
        "  print('Epoch: {:d}'.format(e+1))\n",
        "  print('\\tTraining loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  # print('\\tTest loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "# perform final test step and print the final metrics\n",
        "print('After training:')\n",
        "train_loss, train_accuracy = test_step(net, train_loader, cost_function, device=device)\n",
        "test_loss, test_accuracy = test_step(net, test_loader, cost_function, device=device)\n",
        "print('\\tTraining loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "print('\\tTest loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading of the model and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\OneDrive\\Desktop\\Assignment2\\A2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\nicol\\OneDrive\\Desktop\\Assignment2\\A2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\OneDrive\\Desktop\\Assignment2\\A2\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTraining loss 1.92563, Training accuracy 9.19\n",
            "\tTest loss 2.86072, Test accuracy 7.50\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "model = initialize_alexnet(num_classes=10).to(device)\n",
        "model.load_state_dict(torch.load('state_dict_model.pt', map_location=torch.device(device)))\n",
        "\n",
        "print('After training:')\n",
        "train_loss, train_accuracy = test_step(model, train_loader, cost_function, device=device)\n",
        "test_loss, test_accuracy = test_step(model, test_loader, cost_function, device=device)\n",
        "print('\\tTraining loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "print('\\tTest loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "print('-----------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
